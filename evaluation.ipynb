{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/ToM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration ChristophSchuhmann--MS_COCO_2017_URL_TEXT-14fff710bb0bfd5b\n",
      "Reusing dataset parquet (/home/david/.cache/huggingface/datasets/parquet/ChristophSchuhmann--MS_COCO_2017_URL_TEXT-14fff710bb0bfd5b/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|██████████| 1/1 [00:00<00:00, 451.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# flake8: noqa: E128\n",
    "from asyncore import write\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from distutils.util import strtobool\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gym\n",
    "import wandb\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from referential_game_env import ReferentialGameEnv\n",
    "from speaker import Speaker\n",
    "from tom_speaker import TOMSpeaker\n",
    "from coco_speaker import COCOSpeaker\n",
    "from metrics.metrics import Fluency, SemanticSimilarity, sentence_length, num_nouns\n",
    "from metrics.analysis import pos_count, get_overlap\n",
    "from metrics.compute_bleu import compute_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell to parse all the default args (since there is no command line in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    # fmt: off\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--exp-name', type=str, default=os.path.basename(\"evaluation\"),\n",
    "        help='the name of this experiment')\n",
    "    parser.add_argument('--gym-id', type=str, default=\"ReferentialGame-v0\",\n",
    "        help='the id of the gym environment')\n",
    "    parser.add_argument('--learning-rate', type=float, default=0.0,\n",
    "        help='the learning rate of the optimizer')\n",
    "    parser.add_argument('--seed', type=int, default=1,\n",
    "        help='seed of the experiment')\n",
    "    parser.add_argument('--total-timesteps', type=int, default=10000,\n",
    "        help='total timesteps of the experiments')\n",
    "    parser.add_argument('--torch-deterministic', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help='if toggled, `torch.backends.cudnn.deterministic=False`')\n",
    "    parser.add_argument('--cuda', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help='if toggled, cuda will be enabled by default')\n",
    "    parser.add_argument('--track', type=lambda x:bool(strtobool(x)), default=False, nargs='?', const=True,\n",
    "        help='if toggled, this experiment will be tracked with Weights and Biases')\n",
    "    parser.add_argument('--wandb-project-name', type=str, default=\"ToM-Language-Acquisition-Eval\",\n",
    "        help=\"the wandb's project name\")\n",
    "    parser.add_argument('--wandb-entity', type=str, default=None,\n",
    "        help=\"the entity (team) of wandb's project\")\n",
    "    parser.add_argument('--captions-file', type=str, default=\"data/test_org\",\n",
    "        help=\"file to get auxiliary captions from\")\n",
    "    parser.add_argument('--capture-video', type=lambda x:bool(strtobool(x)), default=False, nargs='?', const=True,\n",
    "        help='weather to capture videos of the agent performances (check out `videos` folder)')\n",
    "    parser.add_argument('--less-logging', type=lambda x:bool(strtobool(x)), default=False, nargs='?', const=True,\n",
    "        help='logs every 1000 timesteps instead of every timestep (recommended for performance)')\n",
    "\n",
    "    # Algorithm specific arguments\n",
    "    parser.add_argument('--num-envs', type=int, default=4,\n",
    "        help='the number of parallel game environments')\n",
    "    parser.add_argument('--num-steps', type=int, default=128,\n",
    "        help='the number of steps to run in each environment per policy rollout')\n",
    "    parser.add_argument('--anneal-lr', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
    "    parser.add_argument('--exp-decay', type=float, default=0.994)\n",
    "    parser.add_argument('--gae', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help='Use GAE for advantage computation')\n",
    "    parser.add_argument('--gamma', type=float, default=1.0,\n",
    "        help='the discount factor gamma')\n",
    "    parser.add_argument('--gae-lambda', type=float, default=0.95,\n",
    "        help='the lambda for the general advantage estimation')\n",
    "    parser.add_argument('--num-minibatches', type=int, default=4,\n",
    "        help='the number of mini-batches')\n",
    "    parser.add_argument('--update-epochs', type=int, default=4,\n",
    "        help=\"the K epochs to update the policy\")\n",
    "    parser.add_argument('--norm-adv', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help=\"Toggles advantages normalization\")\n",
    "    parser.add_argument('--clip-coef', type=float, default=0.2,\n",
    "        help=\"the surrogate clipping coefficient\")\n",
    "    parser.add_argument('--clip-vloss', type=lambda x:bool(strtobool(x)), default=True, nargs='?', const=True,\n",
    "        help='Toggles wheter or not to use a clipped loss for the value function, as per the paper.')\n",
    "    parser.add_argument('--ent-coef', type=float, default=0.01,\n",
    "        help=\"coefficient of the entropy\")\n",
    "    parser.add_argument('--vf-coef', type=float, default=0.5,\n",
    "        help=\"coefficient of the value function\")\n",
    "    parser.add_argument('--max-grad-norm', type=float, default=0.5,\n",
    "        help='the maximum norm for the gradient clipping')\n",
    "    parser.add_argument('--target-kl', type=float, default=None,\n",
    "        help='the target KL divergence threshold')\n",
    "\n",
    "    parser.add_argument('--supervised-coef', type=float, default=0.01, help='the ratio of supervised loss')\n",
    "    parser.add_argument('--length-pen', type=float, default=0.0, help='length penalty')\n",
    "\n",
    "    # tom arguments\n",
    "    parser.add_argument('--use-coco', type=lambda x:bool(strtobool(x)), default = False, nargs='?', \n",
    "        const = True, help = 'toggle usage of COCOSpeaker')\n",
    "    parser.add_argument('--use-tom', type=lambda x:bool(strtobool(x)), default = False, nargs='?', \n",
    "        const = True, help = 'toggle usage of theory of mind')\n",
    "    parser.add_argument('--sigma', type=float, default = 0.0, help = \"exploration sigma value for ToM speaker\")\n",
    "    parser.add_argument('--tom-weight', type=float, default=1.0, \n",
    "        help = \"If using a ToM speaker, what weight to give to ToM listener ranking\")\n",
    "    parser.add_argument('--tom-losscoef', type=float, default=0.1, help = \"coef for tom loss\")\n",
    "    parser.add_argument('--separate-training', type=lambda x:bool(strtobool(x)), default = False, nargs='?',\n",
    "        const = True, help = \"Separate ToM Listener training from rest of network\")\n",
    "    parser.add_argument('--beam-size', type=int, default=25,\n",
    "        help = \"number of candidates to generate for ToM listener\")\n",
    "    parser.add_argument('--beam-search', type=lambda x:bool(strtobool(x)), default = False, nargs = '?',\n",
    "        const = True, help = 'use beam search instead of sampling')\n",
    "    parser.add_argument('--tom-anneal', type=lambda x:bool(strtobool(x)), default = False, nargs='?',\n",
    "        const = True, help = 'toggle anneal of ToM listener influence')\n",
    "    parser.add_argument('--tom-anneal-start', type=float, default=0.2, \n",
    "        help = \"fraction of updates that must pass to start using ToM listener\")\n",
    "    parser.add_argument('--sigma-decay', type=lambda x:bool(strtobool(x)), default = False, nargs='?',\n",
    "        const = True, help = 'toggle anneal of ToM listener influence')\n",
    "    parser.add_argument('--sigma-decay-end', type=float, default=1.0, \n",
    "        help = \"fraction of updates that must pass to converge to final sigma value\")\n",
    "    parser.add_argument('--sigma-low', type=float, default=0.1, \n",
    "        help = \"final sigma value to converge to\")\n",
    "    parser.add_argument('--gold-standard', type=lambda x:bool(strtobool(x)), default = False, nargs='?',\n",
    "        const = True, help = 'give ToM speaker access to gold standard ToM listener')\n",
    "    \n",
    "    # Environment specific arguments\n",
    "    parser.add_argument('--vocabulary-size', type=int, \n",
    "        default=200,\n",
    "        help='vocabulary size of speaker')\n",
    "    parser.add_argument('--max-len', type=int,\n",
    "        default=20,\n",
    "        help='maximum utterance length')\n",
    "    parser.add_argument('--game-file-path', type=str)\n",
    "\n",
    "    parser.add_argument('--theta-1', type=float, default=.4, help='theta 1')\n",
    "    parser.add_argument('--theta-2', type=float, default=.9, help='theta 2')\n",
    "    parser.add_argument('--model-path', type=str, default=None, help='the path of the model')\n",
    "    parser.add_argument('--n-distr', type=int, default=2)\n",
    "    parser.add_argument('--distribution', type=str, default='uniform', help='uniform or zipf')\n",
    "\n",
    "    parser.add_argument('--sup-coef-decay', action='store_true', help='decay supervised coeff')\n",
    "    parser.add_argument('--D_img', type=int, default=2048,)\n",
    "    parser.add_argument('--pretrained-path', type=str, default=None,\n",
    "        help='load in the wandb path for a pretrained model if you want to run in evaluation mode')\n",
    "\n",
    "    parser.add_argument('--render-html', type=lambda x:bool(strtobool(x)), default=False, nargs='?', const=True,\n",
    "        help=\"whether to save HTML images\")\n",
    "    parser.add_argument('--run-name', type=str, default=\"test\",\n",
    "        help=\"run name to save HTML files under\")\n",
    "    parser.add_argument('--render-every-N', type=int, default=5000,\n",
    "        help=\"render an HTML file every N updates\")\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    # fmt: on\n",
    "    return args\n",
    "\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell to adjust the args with the values that were normally set during the commandline (so adjust these if u wanted to alter the command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The arguments you normally set within the command provided in the readme\n",
    "args.total_timesteps = 10000\n",
    "args.supervised_coef = 0.01\n",
    "args.game_file_path = \"data/game_file_dev.pt\"\n",
    "# args.game_file_path = \"data/new_game_file_with_high_similarity.pt\"\n",
    "args.exp_name = \"test1\"\n",
    "args.captions_file = \"data/test_org\"\n",
    "args.less_logging = True\n",
    "args.use_coco = True\n",
    "args.beam_size = 5 # This is the amount of samples to draw for each target, default 10\n",
    "args.prune_size = args.beam_size  # The amount to prune the beams\n",
    "args.beam_search = False\n",
    "# Diverse beam search related\n",
    "args.diverse = False\n",
    "args.diverse_G = 5 # The amount of groups\n",
    "args.diverse_multiplier = 0.01 # The amount the diversity should be taken into account, higher = , lower = more diversity\n",
    "#\n",
    "args.sigma = 0.0\n",
    "args.seed = 517\n",
    "args.tom_weight = 1.0\n",
    "args.pretrained_path = \"andy_files\"\n",
    "args.batch_size = 1\n",
    "#\n",
    "args.max_len = 12 # Default is 20\n",
    "args.render = True\n",
    "args.hard = False\n",
    "#\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, envs):\n",
    "        super(Agent, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            layer_init(\n",
    "                nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(\n",
    "                nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
    "        )\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(x)\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.actor(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiliazation of all the needed stuff happens in the next few cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n",
      "Parsed the provided arguments!\n",
      "Seeding numpy and torch\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "print(\"Parsed the provided arguments!\")\n",
    "################################################################################\n",
    "# Setup Experiment and Logger                                                  #\n",
    "################################################################################\n",
    "if True:\n",
    "    run_name = f\"{args.gym_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "    if args.track:\n",
    "        print(\"Initialising wanDB since tracking is on\")\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            project=args.wandb_project_name,\n",
    "            entity=args.wandb_entity,\n",
    "            sync_tensorboard=True,\n",
    "            config=vars(args),\n",
    "            name=args.exp_name,\n",
    "            monitor_gym=True,\n",
    "            save_code=True,\n",
    "        )\n",
    "################################################################################\n",
    "# Seeding                                                                      #\n",
    "################################################################################\n",
    "if True:\n",
    "    print(\"Seeding numpy and torch\")\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = args.torch_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the referential games!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:02<00:00, 140.13it/s]\n",
      "100%|██████████| 381/381 [00:02<00:00, 140.45it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Referential Game Environments                                                #\n",
    "################################################################################\n",
    "print(\"Creating the referential games!\")\n",
    "envs = ReferentialGameEnv(max_len=args.max_len,\n",
    "                eos_id=3,\n",
    "                noop_penalty=0.5,\n",
    "                length_penalty=args.length_pen,\n",
    "                batch_size=args.batch_size,\n",
    "                n_distr=args.n_distr,\n",
    "                game_file_path=args.game_file_path,\n",
    "                theta_1=args.theta_1,\n",
    "                theta_2=args.theta_2,\n",
    "                distribution=args.distribution,\n",
    "                model_path = args.model_path,\n",
    "                captions_file = args.captions_file,\n",
    "                hard=args.hard)\n",
    "dev_envs = ReferentialGameEnv(max_len=args.max_len,\n",
    "            eos_id=3,\n",
    "            noop_penalty=0.5,\n",
    "            length_penalty=args.length_pen,\n",
    "            batch_size=args.batch_size,\n",
    "            n_distr=args.n_distr,\n",
    "            game_file_path=args.game_file_path,\n",
    "            theta_1=args.theta_1,\n",
    "            theta_2=args.theta_2,\n",
    "            distribution=args.distribution,\n",
    "            model_path = args.model_path,\n",
    "            captions_file = args.captions_file,\n",
    "            hard=args.hard)\n",
    "i2w = torch.load(\"i2w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully created the referential games, now loading the speaker and listeners models!\n",
      "50265\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Device                                                                       #\n",
    "################################################################################\n",
    "if True:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "print(\"Succesfully created the referential games, now loading the speaker and listeners models!\")\n",
    "# Load necessary components such as the agent and tokenizer\n",
    "speaker_path = \"wandb/\" + args.pretrained_path + \"/files/speaker_model.pt\"\n",
    "listener_path = \"wandb/\" + args.pretrained_path + \"/files/tom_listener.pt\"\n",
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "print(tokenizer.vocab_size)\n",
    "print(args.gold_standard)\n",
    "agent = TOMSpeaker(maxlen=args.max_len, vocabsize=tokenizer.vocab_size, \n",
    "                    sigma=args.sigma, beam_size=args.beam_size, tom_weight=args.tom_weight,\n",
    "                    use_pretrained=args.gold_standard, beam_search=args.beam_search,\n",
    "                    loaded_model_paths=(speaker_path, listener_path), use_coco=args.use_coco, word_list=list(range(200))).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here on experiments are ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using beam search\n",
      "<BOS> a baseball player holding a bat on a <UNK> outside of people open\n",
      "<BOS> a baseball player holding a bat on top of a field . <EOS>\n",
      "<BOS> a baseball player holding a bat on a <UNK> outside of food .\n",
      "<BOS> a baseball player holding a bat on a <UNK> outside of people sitting\n",
      "<BOS> a baseball player holding a bat on a area <EOS> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a baseball player holding a bat on a <UNK> outside of people open</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a building with a very large clock on the side of it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a baseball player holding a bat on a field . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a person on some skis in the snow . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000118134.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000266376.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000421908.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a sink and bed a laptop is and white dog . together ball\n",
      "<BOS> a sink and bed a white skateboard <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> a sink and bed a white skateboard . area sign sidewalk . <EOS>\n",
      "<BOS> a sink and bed a white skateboard . area sign sidewalk . area\n",
      "<BOS> a sink and bed a white skateboard . area sign sidewalk . glass\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a sink and bed a white skateboard . area sign sidewalk . area</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a laptop computer sitting on top of a wooden desk . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> two giraffe standing next to each other in a field . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a small room has a bed and desk with a laptop . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000271795.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000122007.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000193194.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a group of a street under beach flying umbrella together glass the ocean\n",
      "<BOS> a man riding a wave on top of a white glass city computer\n",
      "<BOS> a person sitting on a beach with an open umbrella <EOS> <PAD> <PAD>\n",
      "<BOS> a man riding a wave on top of a surfboard . <EOS> <PAD>\n",
      "<BOS> a group of a street under beach flying umbrella together glass to it\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a person sitting on a beach with an open umbrella </p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a person that is holding some food in her hand . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a pizza sitting on top of a table . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a person standing on top of a beach holding an umbrella . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000399510.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000242909.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000532867.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a computer is on top of a table . <EOS> <PAD> <PAD> <PAD>\n",
      "<BOS> an open laptop that is on sitting on top of it near pizza\n",
      "<BOS> an open laptop that is on sitting on top of her bowl table\n",
      "<BOS> an open laptop that is on sitting on top of her glass <EOS>\n",
      "<BOS> an open laptop that is on sitting on top of another laptop .\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a computer is on top of a table . </p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a cat that is sitting in a sink <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a laptop computer sitting on top of a wooden desk . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a couple of people standing next to each other . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000410533.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000271795.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000335153.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a pizza sitting on top of a table eating traffic skis sandwich airplane\n",
      "<BOS> a pizza sitting on top of a table eating food large airplane group\n",
      "<BOS> a pizza sitting on top of a table eating traffic skis table road\n",
      "<BOS> a pizza on top of a bowl <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> a pizza sitting on top of a table eating traffic skis sandwich horse\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a pizza on top of a bowl </p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a person is flying a kite in a field <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a group of people with a cell phone the side of a building . <EOS> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a pizza sitting on top of a white plate on a wooden table . <EOS> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000368242.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000007256.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000448897.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a young men playing a game of frisbee . room . area <EOS>\n",
      "<BOS> a young men playing a game of frisbee . room . together <EOS>\n",
      "<BOS> a young men playing a game of frisbee in <UNK> the child picture\n",
      "<BOS> a young men playing a game of frisbee in <UNK> the child wall\n",
      "<BOS> a young men playing a game of frisbee in <UNK> the child bunch\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a young men playing a game of frisbee . room . area </p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a man flying through while riding a skateboard . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a young boy stands at bat in a park . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a street sign on a road near a building <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000028692.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000548670.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000107244.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a group of people standing on the outside of a building together big\n",
      "<BOS> a group of people standing on the outside of a building . area\n",
      "<BOS> a group of people standing outside <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> a group of people standing on the outside of a building together clock\n",
      "<BOS> a group of people standing on the outside of a building together picture\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a group of people standing on the outside of a building together big</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a white toilet in a very small bathroom . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a city sidewalk with people walking up and down <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a white sink and toilet in a small room . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000489624.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='IMG not found'><br><br>(GOAL) (RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000310532.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a red stop sign sitting on the side of the bowl walking large\n",
      "<BOS> a red stop sign sitting on the side of the glass open <BOS>\n",
      "<BOS> a red stop sign sitting on the side of the bowl walking woman\n",
      "<BOS> a red stop sign sitting next fence outside <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> a man is standing near the street area . <EOS> <PAD> <PAD> <PAD>\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a red stop sign sitting on the side of the bowl walking large</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a blue and white street sign next to a white building . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a man flying through the air while riding a skateboard . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a group of men standing next to each other . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000303942.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000346717.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000039858.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a group of young men playing a game of frisbee together the tree\n",
      "<BOS> a group of people are on the park it <EOS> <PAD> <PAD> <PAD>\n",
      "<BOS> a group of men in <UNK> into skis . together view trees large\n",
      "<BOS> a group of young men playing a game of frisbee <EOS> <PAD> <PAD>\n",
      "<BOS> a group of young men playing a game of frisbee bowl is large\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a group of young men playing a game of frisbee together the tree</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a computer desk with a laptop computer on top of it . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a young man is holding a blue <UNK> <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a group of people on a grass field together playing a game with a frisbee . <EOS> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000164453.jpg'><br></td>\n",
       "\t<td style='text-align: center;'><img src='IMG not found'><br></td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000349926.jpg'><br><br>(GOAL) (RESULT)</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Using beam search\n",
      "<BOS> a man walking a dog under in the open in tree . <EOS>\n",
      "<BOS> a man walking a dog down a road while holding an umbrella .\n",
      "<BOS> a woman a wooden fence walking in front surfboard around eating together glass\n",
      "<BOS> a man walking a dog under in the open in tree walking large\n",
      "<BOS> a man walking a dog under in the table it &apos;s open car\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<body>\n",
       "<h3>Output sentence for game 1:</h3>\n",
       "<p><BOS> a woman a wooden fence walking in front surfboard around eating together glass</p>\n",
       "<h3>Image Results</h3>\n",
       "<table style='width:100%; border-collapse: collapse;'>\n",
       "<tr>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a small dog sitting on a wooden chair . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a group of people standing next to a building with a large dog <EOS> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "\t<td style='padding: 10px; text-align: center;'><BOS> a green white with a sandwich on top of it . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD></td>\n",
       "</tr>\n",
       "<tr>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000461156.jpg'><br><br>(RESULT)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000356406.jpg'><br><br>(GOAL)</td>\n",
       "\t<td style='text-align: center;'><img src='http://images.cocodataset.org/train2017/000000026676.jpg'><br></td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of a total of 10 games is: 0.9\n",
      "The entropy of a total of 10 games is: 0.6449990168213844\n",
      "The unigram count of a total of 10 games is: 0.35821612045428913\n",
      "The bigram count of a total of 10 games is: 0.4237533493056002\n",
      "The trigram count of a total of 10 games is: 0.40675907580837756\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "################################################################################\n",
    "# Evaluation                                                                   #\n",
    "################################################################################\n",
    "total_games = 10\n",
    "accuracy = []\n",
    "entropies = []\n",
    "unigrams = []\n",
    "bigrams = []\n",
    "trigrams = []\n",
    "obs = envs.reset() # Not needed because .step also updates to do a new game\n",
    "for i in range(1, total_games+1):\n",
    "    with torch.no_grad():\n",
    "        # This is to prepare the images for the models\n",
    "        B = obs[\"images\"].shape[0]\n",
    "        next_images = torch.Tensor(\n",
    "                obs[\"images\"][range(B), :]\n",
    "        ).to(device)\n",
    "\n",
    "        # This gets the next target in the reference game\n",
    "        next_target = torch.Tensor(obs[\"goal\"]).long().to(device)\n",
    "\n",
    "        # This creates the sentences, so this makes the Speaker sample sentences based on the images and the target\n",
    "        sentences_tensor, logp, entropy, temp_unigrams, temp_bigrams, temp_trigrams = agent.sample(next_images, next_target, beam_size=args.beam_size, prune_size=args.prune_size, diverse=args.diverse, diverse_G=args.diverse_G, diverse_multiplier=args.diverse_multiplier, render=args.render) # This sentences tensor contains 1 sentence per \"game\"\n",
    "\n",
    "        # These are the generated sentences but as actual sentences, so decoded\n",
    "        generated_sentences = [\n",
    "            ' '.join([i2w[token_id.item()] for token_id in sentence])\n",
    "            for sentence in sentences_tensor\n",
    "        ]\n",
    "\n",
    "        # The env step function makes the listener pick a target based on the given sentences\n",
    "        # Let hierbij op, dat als je render = true op false zet, je geen plaatjes meer zult zien. dit is dus opzich sneller voor alleen accuracy zien\n",
    "        obs = envs.step(sentences_tensor.cpu().numpy(), render=args.render)\n",
    "        dev_accuracy = obs[\"accuracy\"]\n",
    "\n",
    "        # This simply appends the accuracy of this game to the accuracy list of all games\n",
    "        accuracy.append(dev_accuracy)\n",
    "        entropies.append(entropy)\n",
    "        unigrams.append(temp_unigrams[1])\n",
    "        bigrams.append(temp_bigrams[1])\n",
    "        trigrams.append(temp_trigrams[1])\n",
    "        if args.render:\n",
    "            print(\"\\n\\n\\n\")\n",
    "\n",
    "print(\"The accuracy of a total of\", total_games, \"games is:\", (sum(accuracy) / len(accuracy)))\n",
    "print(\"The entropy of a total of\", total_games, \"games is:\", (sum(entropies) / len(entropies)))\n",
    "print(\"The unigram count of a total of\", total_games, \"games is:\", (sum(unigrams) / len(unigrams)))\n",
    "print(\"The bigram count of a total of\", total_games, \"games is:\", (sum(bigrams) / len(bigrams)))\n",
    "print(\"The trigram count of a total of\", total_games, \"games is:\", (sum(trigrams) / len(trigrams)))\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
